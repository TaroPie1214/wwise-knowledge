# 创建声音引擎对象处理器插件

|  |
| --- |
| Wwise SDK 2025.1.4 - Windows |

创建声音引擎对象处理器插件

|  |  |
| --- | --- |
|  | **警告:** 对象处理器是效果器插件的超集，可实现效果器插件的所有功能，还可提供其所不具备的功能。不过，编写起来比较麻烦一些。若不需要同时处理多个 Audio Object，并且无需知道处理的对象而只需了解其音频信号，则应编写效果器插件而非对象处理器（参见 [实现效果器插件接口](soundengine_plugins_effects.html#se_insert_effect) 章节）。 |

# 简介

对象处理器与效果器插件（参见 [实现效果器插件接口](soundengine_plugins_effects.html#se_insert_effect) 章节）类似，两者都是插入到 Wwise 对象所对应 Effect 选项卡的某个插槽中。不过在结合使用 Audio Object 时，其与效果器插件有明显的区别。从本质上来说，效果器插件无法感知 Audio Object ([AkAudioObject](struct_ak_audio_object.html))，而只能处理音频信号；对象处理器则可感知通过总线发送的所有 Audio Object，进而对其进行统一处理并访问相应的元数据。

效果器插件接收单个 AkAudioBuffer，对象处理器则接收 [AkAudioObject](struct_ak_audio_object.html) 实例。该实例提供：

- 一组代表 Audio Object 信号的 [AkAudioBuffer](class_ak_audio_buffer.html) 实例。
- 一组代表 Audio Object 元数据的 [AkAudioObject](struct_ak_audio_object.html) 实例。

下节对这些概念进行了阐释。

# Audio Object：概念

Audio Object 携带有音频信号，单声道或多声道都可以。在 Wwise 中，可通过将总线配置设为 **Audio Objects** 来轻松查看 Audio Object。这些总线称为 Audio Object 总线。Audio Object 总线会汇集 Audio Object 并保留其元数据，而非将其输入混音到单个缓冲区中（无论多声道与否）。Audio Object 总线可灵活地支持不同数量的 Audio Object，非 Audio Object 总线在任意时刻都只支持一个 Audio Object。

Audio Object 的元数据主要由定位信息及一系列自定义元数据构成，其本身就是插件并可由对象处理器插件使用。有关更多详细信息，请参阅 [Audio Object 元数据](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_metadata) 章节。

# 实现对象处理器

在添加到 Audio Object 总线上时，有多少个 Audio Object，效果器插件就会被实例化多少次。各个实例的生命周期与其被指派到的 Audio Object 的生命周期对应。事实上，单个实例不可重复用来轮流处理各个 Audio Object。因为效果器可能需要保持在某个状态，来确保下一帧音频的连续性。

另一方面，无论有多少个 Audio Object，对象处理器都只会被实例化一次。它会一并处理所有这些对象。

对象处理器会依据是否实施原地处理来决定实现 [AK::IAkInPlaceObjectPlugin](class_a_k_1_1_i_ak_in_place_object_plugin.html) 还是 AK::IAkOutOfPlaceObjectPlugin。插件通过 [AK::IAkPlugin::GetPluginInfo](class_a_k_1_1_i_ak_plugin_a5c4cdef6822950045b66834528bd1b55.html#a5c4cdef6822950045b66834528bd1b55) 将 [AkPluginInfo::bCanProcessObjects](struct_ak_plugin_info_abb27da271e4dc15b9b3ef9cb3316cfd3.html#abb27da271e4dc15b9b3ef9cb3316cfd3 "Plug-in can process audio objects. They must implement IAkInPlaceObjectPlugin or IAkOutOfPlaceObjectP...") 设置重置为 true 来声明其为对象处理器，并通过相应地设置 [AkPluginInfo::bIsInPlace](struct_ak_plugin_info_a70fb541431bdc08cdb490a926ccc3ee4.html#a70fb541431bdc08cdb490a926ccc3ee4 "Buffer usage (in-place or not). If true, and the plug-in is an insert effect, it should implement IAk...") 来声明是否实施原地处理。

|  |  |
| --- | --- |
|  | **警告:** 非原地对象处理器仅可添加到总线上。跟总线上的效果器插件一样，其无法改变数据的使用和生成速率（AkPluginInfo::bCanChangeRate 不可为 true）。不过，可更改输出对象及其声道配置。 |

此处仅介绍与这些接口相关的函数。如需了解与其他插件类型共用的接口组件（AK::IAkPlugin 接口），请参阅 [创建声音引擎插件](soundengine_plugins.html) 章节；如需了解与效果器插件共用的功能（如初始化、旁通和监控），请参阅 [实现效果器插件接口](soundengine_plugins_effects.html#se_insert_effect) 章节。

# 实现原地对象处理器

原地对象处理器在 [AK::IAkInPlaceObjectPlugin::Execute](class_a_k_1_1_i_ak_in_place_object_plugin_a5a99693f1b77d56fed6eb36c43ff013f.html#a5a99693f1b77d56fed6eb36c43ff013f) 中接收一组 Audio Object 的缓冲区和元数据（分别对应 [AkAudioBuffer](class_ak_audio_buffer.html) 和 AkAudioObject）。它们能够读取并修改所有 Audio Object 的音频信号和元数据，但无法创建/移除 Audio Object 或更改其声道配置。

Note that when in-place Object Processors are inserted as Effects on objects in the Containers hierarchy, as opposed to on busses, Object Metadata will be invalid during Execute, and any modifications to the Metadata will not be preserved. 对象处理器可通过判断 Object Key 是否等于 AK\_INVALID\_AUDIO\_OBJECT\_ID 来对此予以确认，并决定是要妥善处理这一情况还是直接标记错误。

Compressor 就属于原地对象处理器。它本身需要是对象处理器，因为其算法依赖于即时感知所有 Audio Object 的音频信号。不过，它不会修改 Audio Object 列表。它只会修改通过对象发送的音频信号。

void CAkCompressorFX::Execute(

const [AkAudioObjects](struct_ak_audio_objects.html)& io\_objects // Input objects and object buffers.

)

{

// Downmix Audio Objects' signal into a working buffer "m\_estBuffer",

// perform gain estimation from that buffer and compute a gain to apply to each sample of each Audio Object.

// ...

// Apply compressor gain (samples of m\_estBuffer) to each sample of each Audio Object.

// For each object

for ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) i = 0; i < io\_objects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a); ++i)

{

// For each channel of this object.

const [AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) uNumChannels = io\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[i]->[NumChannels](class_ak_audio_buffer_a4523322478ec9a0f9de0c7c72e65df2f.html#a4523322478ec9a0f9de0c7c72e65df2f)();

for ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) j = 0; j < uNumChannels; ++j)

{

[AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)\* pInBuf = io\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[i]->[GetChannel](class_ak_audio_buffer_ad2bc3b8ddd61eaa0c111798d5f9e8c9c.html#ad2bc3b8ddd61eaa0c111798d5f9e8c9c)(j);

const [AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)\* pInBufEnd = pInBuf + io\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[i]->[uValidFrames](class_ak_audio_buffer_ab7f90fd99119b56e92e4cbf3559f98cd.html#ab7f90fd99119b56e92e4cbf3559f98cd);

[AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)\* estBuf = m\_estBuffer;

while (pInBuf < pInBufEnd)

{

\*pInBuf \*= \*estBuf;

++estBuf;

++pInBuf;

}

}

}

}

Compressor 当然能够处理单个对象。换句话说，它可以应用到传统的基于声道的总线上。因此，我们使用其取代了原有的效果器插件实现。

## 在原地对象处理器中处理尾音

跟效果器插件一样，原地对象处理器可通过将 [AkAudioBuffer::eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc "Execution status") 字段由 AK\_NoMoreData 改为 AK\_DataReady 来按照所需帧数处理尾音。有关更多详细信息，请参阅 [Implementing 效果器插件尾音](soundengine_plugins_effects.html#fx_tails) 章节。不过要注意，对象处理器需要单独处理各个 Audio Object 的尾音。因此，其需要追踪每个对象。

|  |  |
| --- | --- |
|  | **注意:** 不要存储传给 Execute 的 Audio Object 地址，因为每一帧的地址都可能是不一样的。最好使用 [AkAudioObject::key](struct_ak_audio_object_a4b5cc754786f067fa2b3fbed875652d8.html#a4b5cc754786f067fa2b3fbed875652d8 "Unique ID, local to a given bus. Only the lower 56 of 64 bits are used for the object itself....") 字段来识别 Audio Object。 |

# 实现非原地对象处理器

非原地对象处理器在输入端和输出端管理两组不同的 Audio Object。输入端 Audio Object 依托于主机总线，而输出端 Audio Object 由插件以显式方式创建（选用以下章节所述的两种方法）。在每一帧，都会通过 [AK::IAkOutOfPlaceObjectPlugin::Execute](class_a_k_1_1_i_ak_out_of_place_object_plugin_a762b09e1978f3eabdebea17e84581f5a.html#a762b09e1978f3eabdebea17e84581f5a) 将所有这些对象传给插件。

## 非原地对象处理器和总线配置

输出端 Audio Object 的声道配置由插件决定。

从本质上来说，非 Audio Object 总线（或称为单一对象总线）算是一种特殊的 Audio Object 总线。只不过，它仅支持一个 Audio Object。对象处理器可以不加区分地接收和生成任意数量的 Audio Object，因而能让单一对象总线根据情况输出不同数量的 Audio Object。反过来，也能让 Audio Object 输出单个 Audio Object，就像传统的混音总线一样。

|  |  |
| --- | --- |
|  | **备注:** 在插入到非 Audio Object 总线上时，对象处理器在 [AK::IAkEffectPlugin::Init](class_a_k_1_1_i_ak_effect_plugin_ae5a44837c4adddf6ff58fab57453b020.html#ae5a44837c4adddf6ff58fab57453b020) 中接收总线的实际声道配置。因为对象处理器是效果器插件的超集，所以应尽量确保它们能够流畅地工作，无论其是插在 Audio Object 总线上还是非 Audio Object 总线上。也就是说，除非用户错误地将其插入到非 Audio Object 总线上。比如，用户不应将 [Software Binauralizer](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_outofplace_binauralizer) 插件插入到非 Audio Object 总线上，因为下混后的音频不会携带任何有用的定位信息。在这种情况下，最好告知用户其可能执行了错误的操作。 |

## 在非原地对象处理器中处理尾音和对象生命周期

声音引擎会在每帧的开头将所有输入端和输出端 Audio Object 的 [AkAudioBuffer::eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc "Execution status") 重置为 AK\_NoMoreData。若处理之后 [AkAudioBuffer::eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc "Execution status") 仍被设为 AK\_NoMoreData，则将相应的 Audio Object 销毁。在销毁所有输入和输出对象之后，才会将对象处理器销毁。因此，要想让非原地对象处理器在已无任何输入端 Audio Object 的情况下继续输出音频，必须通过将状态设为 AK\_DataReady 来确保让一个或多个输出端 Audio Object 处于活跃状态。

|  |  |
| --- | --- |
|  | **注意:** 在对象处理器内追踪对象时，请务必谨慎。切勿引用已被声音引擎销毁的对象。 |

|  |  |
| --- | --- |
|  | **备注:** 若将 [AkAudioBuffer::eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc "Execution status") 设为 AK\_DataReady，则输入端 Audio Object 将保持活跃状态。不过尽量不要这样做，因为会生成不必要的尾音。 |

|  |  |
| --- | --- |
|  | **备注:** 若没有活跃的输出端 Audio Object，则非原地对象处理器输出无声内容。 |

## 非原地对象处理示例

下面我们来以以下三个范例为参考探讨一下非原地对象处理。

## Software Binauralizer

Software Binauralizer 可作为非原地对象处理器加以实现，来输入多个 Audio Object 并采用立体声声道配置输出单个 Audio Object。这种插件应添加到 Audio Object 总线上，不过可让该总线输出单个立体声信号。

为方便起见，可通过 [AK::IAkEffectPlugin::Init](class_a_k_1_1_i_ak_effect_plugin_ae5a44837c4adddf6ff58fab57453b020.html#ae5a44837c4adddf6ff58fab57453b020) 的握手方法来创建唯一的立体声输出对象。

[AKRESULT](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63) [ObjectBinauralizerFX::Init](namespace_a_k_1_1_comm_a596691b552b507c26b4df958ee1c6de8.html#a596691b552b507c26b4df958ee1c6de8)(

[AK::IAkPluginMemAlloc](class_a_k_1_1_i_ak_plugin_mem_alloc.html)\* in\_pAllocator,

[AK::IAkEffectPluginContext](class_a_k_1_1_i_ak_effect_plugin_context.html)\* in\_pContext,

[AK::IAkPluginParam](class_a_k_1_1_i_ak_plugin_param.html)\* in\_pParams,

[AkAudioFormat](struct_ak_audio_format.html)& io\_rFormat)

{

m\_pContext = in\_pContext;

// in\_rFormat.channelConfig.eConfigType will be different than AK\_ChannelConfigType\_Objects if the configuration of the input of the plugin is known and does not support a

// dynamic number of objects. However this plug-in is pointless if it is not instantiated on an Audio Object bus, so we are better off letting our users know.

if (in\_rFormat.[channelConfig](struct_ak_audio_format_a73de76fa89ed81baa5265448bd6deefe.html#a73de76fa89ed81baa5265448bd6deefe).[eConfigType](struct_ak_channel_config_a598c4a4489e9fb252e7022ae99135674.html#a598c4a4489e9fb252e7022ae99135674) != [AK\_ChannelConfigType\_Objects](_ak_enums_8h_a9e3e31d9ff388daa593222da7672a999.html#a9e3e31d9ff388daa593222da7672a999a338b59e9d7624cbc47fab92e22bc55cc))

return [AK\_UnsupportedChannelConfig](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63a906fa026b1f04805d30bc474677e73ca);

// Inform the host that the output will be stereo. The host will create an output object for us and pass it to Execute.

io\_rFormat.[channelConfig](struct_ak_audio_format_a73de76fa89ed81baa5265448bd6deefe.html#a73de76fa89ed81baa5265448bd6deefe).[SetStandard](struct_ak_channel_config_a4c0f4b3d39608a10c9b330c1ef8281a7.html#a4c0f4b3d39608a10c9b330c1ef8281a7)([AK\_SPEAKER\_SETUP\_STEREO](_ak_speaker_config_8h_a472757ac65daebc42373c503d4c3c894.html#a472757ac65daebc42373c503d4c3c894));

return [AK\_Success](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63ad7c47fea3da641e7422573c6a13dc35e);

}

然后，在 Execute 中插入以下代码：

void ObjectBinauralizerFX::Execute(

const [AkAudioObjects](struct_ak_audio_objects.html)& in\_objects, ///< Input objects and object audio buffers.

const [AkAudioObjects](struct_ak_audio_objects.html)& out\_objects ///< Output objects and object audio buffers.

)

{

[AKASSERT](_ak_assert_8h_ac0e6cc4061c0a7c154a8c921a0af74cb.html#ac0e6cc4061c0a7c154a8c921a0af74cb)(in\_objects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a) > 0); // Should never be called with 0 objects if this plug-in does not force tails.

[AKASSERT](_ak_assert_8h_ac0e6cc4061c0a7c154a8c921a0af74cb.html#ac0e6cc4061c0a7c154a8c921a0af74cb)(out\_objects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a) == 1); // Output config is a stereo channel stream.

// "Binauralize" (just mix) objects in stereo output buffer.

// For the purpose of this demonstration, instead of applying HRTF filters, let's call the built-in service to compute panning gains.

// The output object should be stereo. Clear its two channels.

[AKASSERT](_ak_assert_8h_ac0e6cc4061c0a7c154a8c921a0af74cb.html#ac0e6cc4061c0a7c154a8c921a0af74cb)(out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0]->[GetChannelConfig](class_ak_audio_buffer_a7601d9b814dbcb9dfe2bfbaa05fcb13b.html#a7601d9b814dbcb9dfe2bfbaa05fcb13b)().[uChannelMask](struct_ak_channel_config_a8fc646976d669b0b0bdf81371c2a2f76.html#a8fc646976d669b0b0bdf81371c2a2f76) == [AK\_SPEAKER\_SETUP\_STEREO](_ak_speaker_config_8h_a472757ac65daebc42373c503d4c3c894.html#a472757ac65daebc42373c503d4c3c894));

memset(out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0]->[GetChannel](class_ak_audio_buffer_ad2bc3b8ddd61eaa0c111798d5f9e8c9c.html#ad2bc3b8ddd61eaa0c111798d5f9e8c9c)(0), 0, out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0]->[MaxFrames](class_ak_audio_buffer_a537445dce6e3ed09dd2c337fd73c6b41.html#a537445dce6e3ed09dd2c337fd73c6b41)() \* sizeof([AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)));

memset(out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0]->[GetChannel](class_ak_audio_buffer_ad2bc3b8ddd61eaa0c111798d5f9e8c9c.html#ad2bc3b8ddd61eaa0c111798d5f9e8c9c)(1), 0, out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0]->[MaxFrames](class_ak_audio_buffer_a537445dce6e3ed09dd2c337fd73c6b41.html#a537445dce6e3ed09dd2c337fd73c6b41)() \* sizeof([AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)));

[AKRESULT](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63) eState = [AK\_NoMoreData](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63a94ba10d374d31161770fc490e0245802);

for ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) i = 0; i < in\_objects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a); ++i)

{

// State management: set the output to AK\_DataReady as long as one of the inputs is AK\_DataReady. Otherwise set to AK\_NoMoreData.

if (in\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[i]->[eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc) != [AK\_NoMoreData](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63a94ba10d374d31161770fc490e0245802))

eState = in\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[i]->[eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc);

// Prepare mixing matrix for this input.

const [AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) uNumChannelsIn = in\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[i]->[NumChannels](class_ak_audio_buffer_a4523322478ec9a0f9de0c7c72e65df2f.html#a4523322478ec9a0f9de0c7c72e65df2f)();

[AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) uTransmixSize = [AK::SpeakerVolumes::Matrix::GetRequiredSize](namespace_a_k_1_1_speaker_volumes_1_1_matrix_a59458aba2b1be3fa678021a3aea813b9.html#a59458aba2b1be3fa678021a3aea813b9)(

uNumChannelsIn,

2);

[AK::SpeakerVolumes::MatrixPtr](namespace_a_k_1_1_speaker_volumes_a57e0ce3a8225a58dd886853164554074.html#a57e0ce3a8225a58dd886853164554074) mx = ([AK::SpeakerVolumes::MatrixPtr](namespace_a_k_1_1_speaker_volumes_a57e0ce3a8225a58dd886853164554074.html#a57e0ce3a8225a58dd886853164554074))AkAllocaSIMD(uTransmixSize);

[AK::SpeakerVolumes::Matrix::Zero](namespace_a_k_1_1_speaker_volumes_1_1_matrix_a46351431a388d100fc2676b4aa3dad0c.html#a46351431a388d100fc2676b4aa3dad0c)(mx, uNumChannelsIn, 2);

// Compute panning gains and fill the mixing matrix.

m\_pContext->GetMixerCtx()->ComputePositioning(

in\_objects.[ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853)[i]->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e),

in\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[i]->[GetChannelConfig](class_ak_audio_buffer_a7601d9b814dbcb9dfe2bfbaa05fcb13b.html#a7601d9b814dbcb9dfe2bfbaa05fcb13b)(),

out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0]->[GetChannelConfig](class_ak_audio_buffer_a7601d9b814dbcb9dfe2bfbaa05fcb13b.html#a7601d9b814dbcb9dfe2bfbaa05fcb13b)(),

mx

);

// Using the mixing matrix, mix the channels of the ith input object into the one and only stereo output object.

[AK\_GET\_PLUGIN\_SERVICE\_MIXER](_i_ak_plugin_8h_a4793694b5f18e4334d12f70a4da40e04.html#a4793694b5f18e4334d12f70a4da40e04)(m\_pContext->GlobalContext())->MixNinNChannels(

in\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[i],

out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0],

1.f,

1.f,

mx, /// NOTE: To properly interpolate from frame to frame and avoid any glitch, we would need to store the previous matrix (OR positional information) for each object.

mx);

}

// Set the output object's state.

out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0]->[uValidFrames](class_ak_audio_buffer_ab7f90fd99119b56e92e4cbf3559f98cd.html#ab7f90fd99119b56e92e4cbf3559f98cd) = in\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0]->[MaxFrames](class_ak_audio_buffer_a537445dce6e3ed09dd2c337fd73c6b41.html#a537445dce6e3ed09dd2c337fd73c6b41)();

out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[0]->[eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc) = eState;

}

## 3D Panner

3D Panner 可采用与上述 [Software Binauralizer](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_outofplace_binauralizer) 类似的方式实现。不过，最好还是让它实例化一系列输出端 Audio Object，并使之与空间化虚拟话筒一一对应。如此一来，便可由下游总线或设备来对这些 Audio Object 的信号实施声像摆位，以此充分利用这些虚拟话筒的定位元数据。

在 [AK::IAkEffectPlugin::Init](class_a_k_1_1_i_ak_effect_plugin_ae5a44837c4adddf6ff58fab57453b020.html#ae5a44837c4adddf6ff58fab57453b020) 中，请以显式方式使用 [AK::IAkEffectPluginContext::CreateOutputObjects](class_a_k_1_1_i_ak_effect_plugin_context_a96f65eb02b520f2ca5af497e645971a0.html#a96f65eb02b520f2ca5af497e645971a0) 来创建输出对象，而不要返回非对象配置。

static const int k\_uNumObjectsOut = 6;

[AKRESULT](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63) [Ak3DPannerFX::Init](namespace_a_k_1_1_comm_a596691b552b507c26b4df958ee1c6de8.html#a596691b552b507c26b4df958ee1c6de8)(

[AK::IAkPluginMemAlloc](class_a_k_1_1_i_ak_plugin_mem_alloc.html)\* in\_pAllocator,

[AK::IAkEffectPluginContext](class_a_k_1_1_i_ak_effect_plugin_context.html)\* in\_pContext,

[AK::IAkPluginParam](class_a_k_1_1_i_ak_plugin_param.html)\* in\_pParams,

[AkAudioFormat](struct_ak_audio_format.html)& in\_rFormat

)

{

// Create output objects.

// Desired channel configuration for all new objects: mono.

[AkChannelConfig](struct_ak_channel_config.html) channelConfig;

channelConfig.[SetStandard](struct_ak_channel_config_a4c0f4b3d39608a10c9b330c1ef8281a7.html#a4c0f4b3d39608a10c9b330c1ef8281a7)([AK\_SPEAKER\_SETUP\_MONO](_ak_speaker_config_8h_a15b620987b17cea4c8dca72443f3ac96.html#a15b620987b17cea4c8dca72443f3ac96));

// AkAudioObjects::uNumObjects, the number of objects to create.

// AkAudioObjects::ppObjectBuffers, Returned array of pointers to the object buffers newly created, allocated by the caller. Pass nullptr if they're not needed.

// AkAudioObjects::ppObjects, Returned array of pointers to the objects newly created, allocated by the caller. Pass nullptr if they're not needed.

[AkAudioObject](struct_ak_audio_object.html)\* ppObjects[k\_uNumObjectsOut];

[AkAudioObjects](struct_ak_audio_objects.html) outputObjects;

outputObjects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a) = k\_uNumObjectsOut;

outputObjects.[ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853) = ppObjects;

outputObjects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6) = nullptr; // not needed.

[AKRESULT](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63) res = in\_pContext->[CreateOutputObjects](class_a_k_1_1_i_ak_effect_plugin_context_a96f65eb02b520f2ca5af497e645971a0.html#a96f65eb02b520f2ca5af497e645971a0)(

channelConfig,

outputObjects

);

if (res == [AK\_Success](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63ad7c47fea3da641e7422573c6a13dc35e))

{

// Set output objects' 3D positions as if they were laid out as a 5.1 config around the listener.

// FL

ppObjects[0]->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e).[behavioral](struct_ak_positioning_data_ae7f86a6ffe7166f32371ec765111e8bb.html#ae7f86a6ffe7166f32371ec765111e8bb).[spatMode](struct_ak_behavioral_positioning_data_a135aef56c3da0d202058e13af30ff950.html#a135aef56c3da0d202058e13af30ff950) = [AK\_SpatializationMode\_PositionAndOrientation](_ak_enums_8h_a2091df555ad6110b01ce6905325a3a14.html#a2091df555ad6110b01ce6905325a3a14a9b2c6ba7e49798586faf1e54953c70d0);

ppObjects[0]->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e).[threeD](struct_ak_positioning_data_a835e6eabecf9ecdf86fbf58bfe99d47b.html#a835e6eabecf9ecdf86fbf58bfe99d47b).[xform](struct_ak3d_data_a175ec6a58f0c97ab2070e23eb2b016db.html#a175ec6a58f0c97ab2070e23eb2b016db).[SetPosition](struct_ak_transform_a5213b68637f2d661c1cd811af22bee7d.html#a5213b68637f2d661c1cd811af22bee7d)(-0.707f, 0.f, 0.707f);

// Store the objects' keys so we can later retrieve them (see helper below).

m\_objectKeys[0] = ppObjects[0]->[key](struct_ak_audio_object_a4b5cc754786f067fa2b3fbed875652d8.html#a4b5cc754786f067fa2b3fbed875652d8);

// FR

//...

}

}

// Helper function: find an object having key in\_key in array in\_objects.

static [AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) FindOutputObjectIdx([AkAudioObjectID](_ak_typedefs_8h_a6cadc0376ae4f945438db69f6306f21a.html#a6cadc0376ae4f945438db69f6306f21a) in\_key, [AkAudioObject](struct_ak_audio_object.html)\*\* in\_objects)

{

for (int i = 0; i < k\_uNumObjectsOut; i++)

{

if (in\_objects[i]->key == in\_key)

return i;

}

[AKASSERT](_ak_assert_8h_ac0e6cc4061c0a7c154a8c921a0af74cb.html#ac0e6cc4061c0a7c154a8c921a0af74cb)(false);

return -1;

}

void Ak3DPannerFX::Execute(

const [AkAudioObjects](struct_ak_audio_objects.html)& in\_objects, // Input objects and object audio buffers.

const [AkAudioObjects](struct_ak_audio_objects.html)& out\_objects // Output objects and object audio buffers.

)

{

// Compute panning of each object into a temp buffer tempBuffer.

// ...

// Copy each channel of the temp buffer to its corresponding output object.

[AKASSERT](_ak_assert_8h_ac0e6cc4061c0a7c154a8c921a0af74cb.html#ac0e6cc4061c0a7c154a8c921a0af74cb)(k\_uNumObjectsOut == out\_objects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a));

for (int i = 0; i < k\_uNumObjectsOut; i++)

{

// Find corresponding output object.

// In Execute, the order of objects is not reliable. We need to search for each object in the array of output objects, using the helper defined above.

[AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) idx = FindOutputObjectIdx(m\_objectKeys[i], out\_objects.[ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853));

// Copy the ith temp buffer's channel into the proper output object.

memcpy(out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[idx]->[GetChannel](class_ak_audio_buffer_ad2bc3b8ddd61eaa0c111798d5f9e8c9c.html#ad2bc3b8ddd61eaa0c111798d5f9e8c9c)(0), tempBuffer.GetChannel(i), tempBuffer.uValidFrames \* sizeof([AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)));

// Set the output object's state to avoid garbage collection by the host.

out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[idx]->[uValidFrames](class_ak_audio_buffer_ab7f90fd99119b56e92e4cbf3559f98cd.html#ab7f90fd99119b56e92e4cbf3559f98cd) = tempBuffer.uValidFrames;

out\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[idx]->[eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc) = tempBuffer.eState;

}

}

在上述示例中，您可能会好奇为什么 (-0.707f, 0.f, 0.707f) 代表左前位置。有关详细信息，请参阅 [关于 3D 转换](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_metadata_3dtransform) 章节。

## Particle Generator

对于每个输入端 Audio Object，Particle Generator 可创建 N 个输出端 Audio Object，并将其随机定位在对应对象所在位置的周围。这种对象处理器无法在 Init 中创建对象，而需要在 Execute 中动态地加以创建，同时追踪这些对象及与其对应的输入对象。在输入对象的状态为 AK\_NoMoreData 时，对应输出对象的状态也要设为 AK\_NoMoreData。这样可以确保由声音引擎对对象进行垃圾回收。

|  |  |
| --- | --- |
|  | **注意:** 若非原地对象处理器从 Execute 内调用 AK::IAkEffectPluginContext::CreateOutputObjects，则其无法稳定地访问 out\_objects 中传递的输出对象。在这种情况下，须使用 AK::IAkEffectPluginContext::GetOutputObjects。 |

// The plugin needs to maintain a map of input object keys to generated objects. Like so:

struct GeneratedObjects

{

[AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) numObjs;

[AkAudioObjectID](_ak_typedefs_8h_a6cadc0376ae4f945438db69f6306f21a.html#a6cadc0376ae4f945438db69f6306f21a) apObjectKeys[AK\_MAX\_GENERATED\_OBJECTS];

int index; /// We use an index mark each output object as "visited" and map them to input objects (index in the array) at the same time.

};

[AkMixerInputMap<AkUInt64,GeneratedObjects>](class_ak_mixer_input_map.html) m\_mapInObjsToOutObjs;

void ParticleGeneratorFX::Execute(

const [AkAudioObjects](struct_ak_audio_objects.html)& in\_objects, ///< Input objects and object audio buffers.

const [AkAudioObjects](struct_ak_audio_objects.html)& out\_objects ///< Output objects and object audio buffers.

)

{

[AKASSERT](_ak_assert_8h_ac0e6cc4061c0a7c154a8c921a0af74cb.html#ac0e6cc4061c0a7c154a8c921a0af74cb)(in\_objects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a) > 0); // Should never be called with 0 objects if this plug-in supports no tail.

// Object bookkeeping.

for ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) i = 0; i < in\_objects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a); ++i)

{

// Find this object in our map.

[AkAudioObject](struct_ak_audio_object.html) \* inobj = in\_objects.[ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853)[i];

GeneratedObjects \* pEntry = m\_mapInObjsToOutObjs.[Exists](class_ak_mixer_input_map_ad9acf848722f5fb49c1184fc89aff4a2.html#ad9acf848722f5fb49c1184fc89aff4a2)(inobj->[key](struct_ak_audio_object_a4b5cc754786f067fa2b3fbed875652d8.html#a4b5cc754786f067fa2b3fbed875652d8));

if (pEntry)

pEntry->index = i; // Found. Note down the index for later.

else

{

// New. Create a new entry and new associated output objects.

pEntry = m\_mapInObjsToOutObjs.[AddInput](class_ak_mixer_input_map_aa8e0ad3d5ecd8a24cc4c5011b4ffb1c9.html#aa8e0ad3d5ecd8a24cc4c5011b4ffb1c9)(inobj->[key](struct_ak_audio_object_a4b5cc754786f067fa2b3fbed875652d8.html#a4b5cc754786f067fa2b3fbed875652d8));

if (pEntry)

{

[AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) numObjsOut = 1;

if (inobj->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e).[behavioral](struct_ak_positioning_data_ae7f86a6ffe7166f32371ec765111e8bb.html#ae7f86a6ffe7166f32371ec765111e8bb).[spatMode](struct_ak_behavioral_positioning_data_a135aef56c3da0d202058e13af30ff950.html#a135aef56c3da0d202058e13af30ff950) != [AK\_SpatializationMode\_None](_ak_enums_8h_a2091df555ad6110b01ce6905325a3a14.html#a2091df555ad6110b01ce6905325a3a14a1564e597be0cedb081025e92cd29aad2))

{

// If "3D".

// Create between one and AK\_MAX\_GENERATED\_OBJECTS output objects.

[AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98) fRandom = rand() / (([AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98))RAND\_MAX);

numObjsOut = ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce))(fRandom \* (AK\_MAX\_GENERATED\_OBJECTS - 1) + 1.f);

}

// Else just create one object.

[AkAudioObject](struct_ak_audio_object.html) \*\* arNewObjects = ([AkAudioObject](struct_ak_audio_object.html)\*\*)AkAlloca(numObjsOut \* sizeof([AkAudioObject](struct_ak_audio_object.html)\*));

[AkAudioObjects](struct_ak_audio_objects.html) outputObjects;

outputObjects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a) = numObjsOut;

outputObjects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6) = nullptr;

outputObjects.[ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853) = arNewObjects;

if (m\_pContext->CreateOutputObjects(in\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[i]->[GetChannelConfig](class_ak_audio_buffer_a7601d9b814dbcb9dfe2bfbaa05fcb13b.html#a7601d9b814dbcb9dfe2bfbaa05fcb13b)(), outputObjects) == [AK\_Success](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63ad7c47fea3da641e7422573c6a13dc35e))

{

for ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) iObj = 0; iObj < numObjsOut; iObj++)

{

[AkAudioObject](struct_ak_audio_object.html) \* pObject = arNewObjects[iObj];

pEntry->apObjectKeys[iObj] = pObject->[key](struct_ak_audio_object_a4b5cc754786f067fa2b3fbed875652d8.html#a4b5cc754786f067fa2b3fbed875652d8);

// Copy the input object's positional metadata, but randomize the actual position.

pObject->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e).[behavioral](struct_ak_positioning_data_ae7f86a6ffe7166f32371ec765111e8bb.html#ae7f86a6ffe7166f32371ec765111e8bb).[spatMode](struct_ak_behavioral_positioning_data_a135aef56c3da0d202058e13af30ff950.html#a135aef56c3da0d202058e13af30ff950) = inobj->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e).[behavioral](struct_ak_positioning_data_ae7f86a6ffe7166f32371ec765111e8bb.html#ae7f86a6ffe7166f32371ec765111e8bb).[spatMode](struct_ak_behavioral_positioning_data_a135aef56c3da0d202058e13af30ff950.html#a135aef56c3da0d202058e13af30ff950);

pObject->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e).[threeD](struct_ak_positioning_data_a835e6eabecf9ecdf86fbf58bfe99d47b.html#a835e6eabecf9ecdf86fbf58bfe99d47b) = inobj->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e).[threeD](struct_ak_positioning_data_a835e6eabecf9ecdf86fbf58bfe99d47b.html#a835e6eabecf9ecdf86fbf58bfe99d47b);

// Randomize position and assign to output object.

/// NOTE: By randomizing position now at object creation time and not updating it with inobj->positioning, particles will remain fixed with the listener's head throughout their

/// existence. We could choose to instead store an offset in our map and apply it to inobj at each frame.

[AkVector](struct_ak_vector.html) pos = ComputeRandomPosition(inobj->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e).[threeD](struct_ak_positioning_data_a835e6eabecf9ecdf86fbf58bfe99d47b.html#a835e6eabecf9ecdf86fbf58bfe99d47b).[xform](struct_ak3d_data_a175ec6a58f0c97ab2070e23eb2b016db.html#a175ec6a58f0c97ab2070e23eb2b016db).[Position](struct_ak_transform_a1b2697d425ca3e8e0a5fb0faee87fcd5.html#a1b2697d425ca3e8e0a5fb0faee87fcd5)());

pObject->[positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e).[threeD](struct_ak_positioning_data_a835e6eabecf9ecdf86fbf58bfe99d47b.html#a835e6eabecf9ecdf86fbf58bfe99d47b).[xform](struct_ak3d_data_a175ec6a58f0c97ab2070e23eb2b016db.html#a175ec6a58f0c97ab2070e23eb2b016db).[SetPosition](struct_ak_transform_a5213b68637f2d661c1cd811af22bee7d.html#a5213b68637f2d661c1cd811af22bee7d)(pos);

}

pEntry->numObjs = numObjsOut;

pEntry->index = i;

}

}

}

}

// Copy input objects' signal to corresponding output objects. Garbage collect objects (on our side) along the way.

// We cannot use out\_objects because we changed the collection of objects during this call!Use GetOutputObjects instead.

// First, query the number of objects.

[AkAudioObjects](struct_ak_audio_objects.html) outputObjects;

outputObjects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a) = 0;

outputObjects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6) = nullptr;

outputObjects.[ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853) = nullptr;

m\_pContext->GetOutputObjects(outputObjects);

if (outputObjects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a) > 0)

{

// Allocate arrays on the stack and retrieve the output objects.

[AkAudioBuffer](class_ak_audio_buffer.html) \*\* buffersOut = ([AkAudioBuffer](class_ak_audio_buffer.html) \*\*)AkAlloca(outputObjects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a) \* sizeof([AkAudioBuffer](class_ak_audio_buffer.html)\*));

[AkAudioObject](struct_ak_audio_object.html) \*\* objectsOut = ([AkAudioObject](struct_ak_audio_object.html) \*\*)AkAlloca(outputObjects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a) \* sizeof([AkAudioObject](struct_ak_audio_object.html)\*));

m\_pContext->GetOutputObjects(outputObjects);

// Iterate through our internal map.

[AkMixerInputMap<AkAudioObjectID, GeneratedObjects>::Iterator](class_ak_mixer_input_map.html) it = m\_mapInObjsToOutObjs.[Begin](class_ak_array_a3586641c10c90cdcbd2c67edc5361309.html#a3586641c10c90cdcbd2c67edc5361309)();

while (it != m\_mapInObjsToOutObjs.[End](class_ak_array_a8b3f475890ba0b28b1ee26ef26835789.html#a8b3f475890ba0b28b1ee26ef26835789)())

{

// Has the input object been passed to Execute?

if ((\*it).pUserData->index >= 0)

{

// Yes. Copy its signal into each of its associated output objects.

[AkAudioBuffer](class_ak_audio_buffer.html)\* inbuf = in\_objects.[ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)[(\*it).pUserData->index];

const [AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) uNumChannels = inbuf->[NumChannels](class_ak_audio_buffer_a4523322478ec9a0f9de0c7c72e65df2f.html#a4523322478ec9a0f9de0c7c72e65df2f)();

for ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) out = 0; out < (\*it).pUserData->numObjs; out++)

{

// Find output object.

[AkAudioBuffer](class_ak_audio_buffer.html) \* pBufferOut = nullptr;

[AkAudioObject](struct_ak_audio_object.html) \* pObjOut = nullptr;

for ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) i = 0; i < outputObjects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a); i++)

{

if (objectsOut[i]->key == (\*it).pUserData->apObjectKeys[out])

{

pBufferOut = buffersOut[i];

pObjOut = objectsOut[i];

break;

}

}

if (pObjOut)

{

// Copy each channel.

for ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) j = 0; j < uNumChannels; ++j)

{

[AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)\* pInBuf = inbuf->[GetChannel](class_ak_audio_buffer_ad2bc3b8ddd61eaa0c111798d5f9e8c9c.html#ad2bc3b8ddd61eaa0c111798d5f9e8c9c)(j);

[AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)\* outBuf = pBufferOut->[GetChannel](class_ak_audio_buffer_ad2bc3b8ddd61eaa0c111798d5f9e8c9c.html#ad2bc3b8ddd61eaa0c111798d5f9e8c9c)(j);

memcpy(outBuf, pInBuf, inbuf->[uValidFrames](class_ak_audio_buffer_ab7f90fd99119b56e92e4cbf3559f98cd.html#ab7f90fd99119b56e92e4cbf3559f98cd) \* sizeof([AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)));

}

// Copy state.

pBufferOut->[uValidFrames](class_ak_audio_buffer_ab7f90fd99119b56e92e4cbf3559f98cd.html#ab7f90fd99119b56e92e4cbf3559f98cd) = inbuf->[uValidFrames](class_ak_audio_buffer_ab7f90fd99119b56e92e4cbf3559f98cd.html#ab7f90fd99119b56e92e4cbf3559f98cd);

pBufferOut->[eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc) = inbuf->[eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc);

// Also, since there is a clear association of input objects to output objects, let's propagate the associated input object's custom metadata to the output.

pObjOut->[arCustomMetadata](struct_ak_audio_object_a40f457c25d198d643eb3a93fd844771f.html#a40f457c25d198d643eb3a93fd844771f).[Copy](class_ak_array_a8a436cce42c404496e6ebb19072581e6.html#a8a436cce42c404496e6ebb19072581e6)(in\_objects.[ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853)[(\*it).pUserData->index]->[arCustomMetadata](struct_ak_audio_object_a40f457c25d198d643eb3a93fd844771f.html#a40f457c25d198d643eb3a93fd844771f));

}

}

(\*it).pUserData->index = -1; // "clear" index for next frame.

++it;

}

else

{

// Destroy stale objects.

// Output objects are collected by the host if we don't set their eState explicitly to AK\_DataReady.

// However, here we need to get rid of them on our side otherwise our map would grow indefinitely.

it = m\_mapInObjsToOutObjs.[EraseSwap](class_ak_mixer_input_map_ad839b271ff3a2213765456cefd569e5c.html#ad839b271ff3a2213765456cefd569e5c)(it);

}

}

}

}

## 为 Audio Object 指派名称

在设计工具的 Audio Object Profiler 中，会将发起端 Wwise 对象的名称赋予 Audio Object。相应地，非原地对象处理器的输出对象全部使用其所在总线的名称。为方便实施性能分析，建议在适用情况下使用 [AkAudioObject::SetName](struct_ak_audio_object_a0254e6325540e0edec1c72a19a39d70d.html#a0254e6325540e0edec1c72a19a39d70d) 来为输出对象指派名称。

比如，在上述 [3D Panner](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_outofplace_panner) 中创建对象时，可按照以下方式进行命名：

// FL

ppObjects[0]->[SetName](struct_ak_audio_object_a0254e6325540e0edec1c72a19a39d70d.html#a0254e6325540e0edec1c72a19a39d70d)(in\_pAllocator, "FL");

//...

# Audio Object 元数据

[AkAudioObject](struct_ak_audio_object.html) 结构包含整条对象管线中随 Audio Object 音频缓冲区一并传输的所有 Audio Object 元数据。其可分为三个类别：

- 标识：AkAudioObject::key、AkAudioObject::instigatorID 和 AkAudioObject::objectName。它们绝对不能由对象处理器写入。只有 objectName 可由对象处理器使用 [AkAudioObject::SetName](struct_ak_audio_object_a0254e6325540e0edec1c72a19a39d70d.html#a0254e6325540e0edec1c72a19a39d70d) 来设置。
- 定位信息：AkAudioObject::positioning（参见下文 [定位元数据](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_metadata_positioning) 章节）。
- 累积增益：AkAudioObject::cumulativeGain（参见下文 [Cumulative Gain 元数据](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_metadata_cumulativegain) 章节）。
- 自定义元数据插件：AkAudioObject::arCustomMetadata（参见下文 [自定义元数据插件](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_metadata_custom) 章节）。

## 定位元数据

Audio Object 在 [AkAudioObject::positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e "Positioning data for deferred 3D rendering.") 中携带发起端声音的定位数据。`AkAudioObject::positioning.behavioral` 保存 Wwise 对象上可设定的所有相关定位设置。比如，若声音使用扬声器声像摆位，则 `AkAudioObject::positioning.behavioral.panType` 将被设为其中一种声像摆位器类型，`panLR` 、`panBF` 和 `panDU` 将与声像摆位器的位置对应。

若空间化模式为 3D（(`AK_SpatializationMode_PositionOnly` 或 `AK_SpatializationMode_PositionAndOrientation` ），则 `AkAudioObject::positioning.threeD` 包含所有与 3D 位置相关的数据：

- `AkAudioObject::positioning.threeD.xform` 一般会沿用关联游戏对象的位置。不过，可依据其 3D 定位设置（如 3D Automation）来针对各个声音加以修改或覆盖。
- `AkAudioObject::positioning.threeD.spread` 和 `AkAudioObject::positioning.threeD.focus` 一般通过 Attenuation 曲线来进行计算。

## Cumulative Gain 元数据

Audio Object 具有上游所应用的累积增益，比如音频源的 Volume 设置或来自总线和总线通路的增益变化。对于没有效果器或对象处理器的简单场景，这意味着在最终下混到扬声器 Bed 或作为 Audio Object 发送到系统输出之前不会将 Audio Object 应用于其音频信号。这样可以避免在一帧中多次调节增益并逐步应用于 Audio Object 的音频信号以确保混音平滑变化，尤其是在因 Game Object 添加或移除位置而创建和销毁 Audio Object 的情况下。

针对此元数据的支持对对象处理器来说是可选的，其可通过在对象处理器对 `IAkPlugin::GetPluginInfo` 的实现中将 `IAkPluginInfo::bUsesGainAttribute` 设为 true 来启用。若 bUsesGainAttribute 保留为 false，则所有传给 Execute 的音频缓冲区将具有在执行之前应用于 Audio Object 的累积增益，而传给对象处理器的增益将取中立值。倘若将 bUsesGainAttribute 设为 true，则不会修改音频缓冲区，累积增益可为无单位值。藉此，对象处理器可根据需要确认增益并修改 Audio Object 的累积增益。

若要修改 Audio Object 的累积增益，请注意该值为 `AkRamp` 且游戏引擎不会自动处理某一帧 fNext 值和下一帧 fPrev 值之间的连贯性。也就是说，若对象处理器要修改某一帧的 fNext，则须将同样的修改应用于下一帧的 fPrev。倘若管理不当，在音频管线的其他部分需要消耗 Audio Object 的增益时，可能会出现毛刺噪声或音频信号断续问题。

## 关于 3D 转换

若空间化模式 `AkAudioObject::positioning.behavioral.spatMode` 为3D（`AK_SpatializationMode_PositionOnly` 或 `AK_SpatializationMode_PositionAndOrientation` ），则将对 3D 位置实施转换（变换和旋转）以使其与所在总线关联的游戏对象（听者）相对。比如，声音可以定位在 (2, 0, 0)；在由与处于 (10, 0, 0) 的听者关联的 Audio Object 总线处理时，将把生成的 Audio Object 定位在 (-8, 0, 0)。该总线上的对象处理器会将所述 Audio Object 视为处在 (-8, 0, 0) 位置。

Wwise 中采用左手坐标系，默认朝向的前向矢量指向 Z，顶向矢量指向 Y（由 [AkCommonDefs.h](_ak_common_defs_8h.html) 定义）。

/// Default listener transform.

#define AK\_DEFAULT\_LISTENER\_POSITION\_X (0.0f) // at coordinate system's origin

#define AK\_DEFAULT\_LISTENER\_POSITION\_Y (0.0f)

#define AK\_DEFAULT\_LISTENER\_POSITION\_Z (0.0f)

#define AK\_DEFAULT\_LISTENER\_FRONT\_X (0.0f) // looking toward Z,

#define AK\_DEFAULT\_LISTENER\_FRONT\_Y (0.0f)

#define AK\_DEFAULT\_LISTENER\_FRONT\_Z (1.0f)

#define AK\_DEFAULT\_TOP\_X (0.0f) // top towards Y

#define AK\_DEFAULT\_TOP\_Y (1.0f)

#define AK\_DEFAULT\_TOP\_Z (0.0f)

比如，对于 [Software Binauralizer](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_outofplace_binauralizer) ，已在到达插件之前对输入对象进行旋转，以使 Z 轴正半轴指向听者前方，X 轴正半轴指向其右方，以此类推。正因如此，示例中使用的 [AK::IAkMixerPluginContext::ComputePositioning](class_a_k_1_1_i_ak_mixer_plugin_context_a0d39528d0bf01ec4e08bc20956dfce2c.html#a0d39528d0bf01ec4e08bc20956dfce2c) 服务才不会采用听者的朝向，而是假定为默认朝向。

因此，在上述 [3D Panner](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_outofplace_panner) 示例中，(-0.707, 0, 0.707) 指向与所在总线关联的游戏对象左前 45 度。

## 自定义元数据插件

对象处理器能够访问与 Audio Object 绑定的自定义元数据。

自定义元数据是种只包含一组参数的插件。在设计工具中，元数据插件可添加到任何 Wwise 对象上，并且支持 ShareSet。在声音引擎中，其实现 [AK::IAkPluginParam](class_a_k_1_1_i_ak_plugin_param.html) 接口。

在适用情况下，Audio Object 会在每一帧收集与发起端声音绑定的所有元数据插件，并将其添加到 [AkAudioObject::arCustomMetadata](struct_ak_audio_object_a40f457c25d198d643eb3a93fd844771f.html#a40f457c25d198d643eb3a93fd844771f "Array of custom metadata, gathered from visited objects. Note: any custom metadata is expected to exi...") 数组。然后，收集与流经的每条总线绑定的所有元数据插件。对象处理器（无论原地还是非原地）可读取此数组。当然，必须知晓插件才能转译其内容。

对象处理器实现类可写入一个或多个配套元数据插件，便于用户添加到 Wwise 对象。

比如，在前述 Software Binauralizer 中（参见 [Software Binauralizer](soundengine_plugins_objectprocessor.html#soundengine_plugins_objectprocessor_outofplace_binauralizer) 章节），想要支持直通模式，以避免对某些声音实施 HRTF 滤波。为此，可使用名为 Passthrough 的布尔值属性来创建配套元数据插件 ObjectBinauralizerMetadata。这样的话用户就可以将此插件添加到任何想要禁用 HRTF 的 Wwise 对象。然后，在对象处理器的 Execute() 中插入以下代码：

for ([AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce) i = 0; i < in\_objects.[uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a); ++i)

{

// Assume that Passthrough Mode is false if there isn't an ObjectBinauralizerMetadata metadata on the Audio Object.

bool bPassthrough = false;

// Search for it.

for (AkAudioObject::ArrayCustomMetadata::Iterator it = in\_objects.[ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853)[i]->[arCustomMetadata](struct_ak_audio_object_a40f457c25d198d643eb3a93fd844771f.html#a40f457c25d198d643eb3a93fd844771f).[Begin](class_ak_array_a3586641c10c90cdcbd2c67edc5361309.html#a3586641c10c90cdcbd2c67edc5361309)(); it != in\_objects.[ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853)[i]->[arCustomMetadata](struct_ak_audio_object_a40f457c25d198d643eb3a93fd844771f.html#a40f457c25d198d643eb3a93fd844771f).[End](class_ak_array_a8b3f475890ba0b28b1ee26ef26835789.html#a8b3f475890ba0b28b1ee26ef26835789)(); ++it)

{

if ((\*it).pluginID == [AKMAKECLASSID](_ak_common_defs_8h_ac73a5e1e4a45a0aeea1b11b08ba93516.html#ac73a5e1e4a45a0aeea1b11b08ba93516)([AkPluginTypeMetadata](_ak_enums_8h_af1a95e76b0e2a003e7edb2ad6f4043f4.html#af1a95e76b0e2a003e7edb2ad6f4043f4a805da301d83f3e29583c5199ccb66f66), MYCOMPANYID, OBJECT\_BINAURALIZER\_METADATA\_ID))

{

// The metadata plugin ID matches the type we are looking for. We can thus safely cast the AK::IAkPluginParam to a known type.

ObjectBinauralizerMetadata \* pMetadata = (ObjectBinauralizerMetadata\*)(\*it).pParam;

bPassthrough = pMetadata->bPassthrough;

}

}

// Do something with bPassthrough

// ...

}

|  |  |
| --- | --- |
|  | **备注:** 因为 Audio Object 从访问过的每个 Wwise 对象收集元数据插件，所以单个 Audio Object 上的同一插件类型可能会存在多个实例。在这种情况下，需要由您决定采用怎样的策略，并相应的信息告知用户。 |

[AK\_SPEAKER\_SETUP\_MONO](_ak_speaker_config_8h_a15b620987b17cea4c8dca72443f3ac96.html#a15b620987b17cea4c8dca72443f3ac96)

#define AK\_SPEAKER\_SETUP\_MONO

1.0 setup channel mask

**Definition:** [AkSpeakerConfig.h:63](_ak_speaker_config_8h_source.html#l00063)

[AkAudioBuffer::GetChannel](class_ak_audio_buffer_ad2bc3b8ddd61eaa0c111798d5f9e8c9c.html#ad2bc3b8ddd61eaa0c111798d5f9e8c9c)

AkSampleType \* GetChannel(AkUInt32 in\_uIndex)

**Definition:** [AkCommonDefs.h:421](_ak_common_defs_8h_source.html#l00421)

[AkAudioObject::positioning](struct_ak_audio_object_a1dccda4d0468b93e4347842a9de4e98e.html#a1dccda4d0468b93e4347842a9de4e98e)

AkPositioningData positioning

Positioning data for deferred 3D rendering.

**Definition:** [AkAudioObject.h:67](_ak_audio_object_8h_source.html#l00067)

[AkAudioBuffer::GetChannelConfig](class_ak_audio_buffer_a7601d9b814dbcb9dfe2bfbaa05fcb13b.html#a7601d9b814dbcb9dfe2bfbaa05fcb13b)

AkForceInline AkChannelConfig GetChannelConfig() const

**Definition:** [AkCommonDefs.h:348](_ak_common_defs_8h_source.html#l00348)

[AkArray::Copy](class_ak_array_a8a436cce42c404496e6ebb19072581e6.html#a8a436cce42c404496e6ebb19072581e6)

AKRESULT Copy(const AkArray< T, ARG\_T, TAlloc, TGrowBy, TMovePolicy > &in\_rSource)

**Definition:** [AkArray.h:867](_ak_array_8h_source.html#l00867)

[AK::IAkPluginParam](class_a_k_1_1_i_ak_plugin_param.html)

**Definition:** [IAkPlugin.h:709](_i_ak_plugin_8h_source.html#l00708)

[AkAudioObject::key](struct_ak_audio_object_a4b5cc754786f067fa2b3fbed875652d8.html#a4b5cc754786f067fa2b3fbed875652d8)

AkAudioObjectID key

Unique ID, local to a given bus. Only the lower 56 of 64 bits are used for the object itself....

**Definition:** [AkAudioObject.h:65](_ak_audio_object_8h_source.html#l00065)

[AkAudioBuffer::NumChannels](class_ak_audio_buffer_a4523322478ec9a0f9de0c7c72e65df2f.html#a4523322478ec9a0f9de0c7c72e65df2f)

AkForceInline AkUInt32 NumChannels() const

Get the number of channels.

**Definition:** [AkCommonDefs.h:337](_ak_common_defs_8h_source.html#l00337)

[AkChannelConfig](struct_ak_channel_config.html)

**Definition:** [AkSpeakerConfig.h:436](_ak_speaker_config_8h_source.html#l00435)

[AkChannelConfig::uChannelMask](struct_ak_channel_config_a8fc646976d669b0b0bdf81371c2a2f76.html#a8fc646976d669b0b0bdf81371c2a2f76)

AkUInt32 uChannelMask

Channel mask (configuration).

**Definition:** [AkSpeakerConfig.h:446](_ak_speaker_config_8h_source.html#l00446)

[AK::SpeakerVolumes::Matrix::GetRequiredSize](namespace_a_k_1_1_speaker_volumes_1_1_matrix_a59458aba2b1be3fa678021a3aea813b9.html#a59458aba2b1be3fa678021a3aea813b9)

AkForceInline AkUInt32 GetRequiredSize(AkUInt32 in\_uNumChannelsIn, AkUInt32 in\_uNumChannelsOut)

**Definition:** [AkSpeakerVolumes.h:303](_ak_speaker_volumes_8h_source.html#l00303)

[AkAudioFormat::channelConfig](struct_ak_audio_format_a73de76fa89ed81baa5265448bd6deefe.html#a73de76fa89ed81baa5265448bd6deefe)

AkChannelConfig channelConfig

Channel configuration.

**Definition:** [AkCommonDefs.h:64](_ak_common_defs_8h_source.html#l00064)

[AK::SpeakerVolumes::Matrix::Zero](namespace_a_k_1_1_speaker_volumes_1_1_matrix_a46351431a388d100fc2676b4aa3dad0c.html#a46351431a388d100fc2676b4aa3dad0c)

AkForceInline void Zero(MatrixPtr in\_pVolumes, AkUInt32 in\_uNumChannelsIn, AkUInt32 in\_uNumChannelsOut)

**Definition:** [AkSpeakerVolumes.h:339](_ak_speaker_volumes_8h_source.html#l00339)

[AK::Comm::Init](namespace_a_k_1_1_comm_a596691b552b507c26b4df958ee1c6de8.html#a596691b552b507c26b4df958ee1c6de8)

AKSOUNDENGINE\_API AKRESULT Init(const AkCommSettings &in\_settings)

[AkTransform::SetPosition](struct_ak_transform_a5213b68637f2d661c1cd811af22bee7d.html#a5213b68637f2d661c1cd811af22bee7d)

void SetPosition(const AkVector &in\_position)

Set position.

**Definition:** [Ak3DObjects.h:321](_ak3_d_objects_8h_source.html#l00321)

[AK\_SpatializationMode\_PositionAndOrientation](_ak_enums_8h_a2091df555ad6110b01ce6905325a3a14.html#a2091df555ad6110b01ce6905325a3a14a9b2c6ba7e49798586faf1e54953c70d0)

@ AK\_SpatializationMode\_PositionAndOrientation

Spatialization based on both emitter position and emitter orientation.

**Definition:** [AkEnums.h:256](_ak_enums_8h_source.html#l00256)

[AkReal32](_ak_numeral_types_8h_afc38459f26e2b23defe588026e886a98.html#afc38459f26e2b23defe588026e886a98)

float AkReal32

32-bit floating point

**Definition:** [AkNumeralTypes.h:43](_ak_numeral_types_8h_source.html#l00043)

[AkAudioBuffer::eState](class_ak_audio_buffer_a069d15381980ac4851216e084cf6a0cc.html#a069d15381980ac4851216e084cf6a0cc)

AKRESULT eState

Execution status

**Definition:** [AkCommonDefs.h:496](_ak_common_defs_8h_source.html#l00496)

[AK\_GET\_PLUGIN\_SERVICE\_MIXER](_i_ak_plugin_8h_a4793694b5f18e4334d12f70a4da40e04.html#a4793694b5f18e4334d12f70a4da40e04)

#define AK\_GET\_PLUGIN\_SERVICE\_MIXER(plugin\_ctx)

**Definition:** [IAkPlugin.h:1984](_i_ak_plugin_8h_source.html#l01984)

[AkAudioBuffer::uValidFrames](class_ak_audio_buffer_ab7f90fd99119b56e92e4cbf3559f98cd.html#ab7f90fd99119b56e92e4cbf3559f98cd)

AkUInt16 uValidFrames

Number of valid sample frames in the audio buffer

**Definition:** [AkCommonDefs.h:502](_ak_common_defs_8h_source.html#l00502)

[AkPluginTypeMetadata](_ak_enums_8h_af1a95e76b0e2a003e7edb2ad6f4043f4.html#af1a95e76b0e2a003e7edb2ad6f4043f4a805da301d83f3e29583c5199ccb66f66)

@ AkPluginTypeMetadata

Metadata plug-in: applies object-based processing to audio data

**Definition:** [AkEnums.h:291](_ak_enums_8h_source.html#l00291)

[AkAudioObject](struct_ak_audio_object.html)

**Definition:** [AkAudioObject.h:46](_ak_audio_object_8h_source.html#l00045)

[AK\_NoMoreData](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63a94ba10d374d31161770fc490e0245802)

@ AK\_NoMoreData

No more data is available from the source.

**Definition:** [AkEnums.h:45](_ak_enums_8h_source.html#l00045)

[AkAudioObject::SetName](struct_ak_audio_object_a0254e6325540e0edec1c72a19a39d70d.html#a0254e6325540e0edec1c72a19a39d70d)

AKRESULT SetName(AK::IAkPluginMemAlloc \*in\_pAllocator, const char \*in\_szName)

**Definition:** [AkAudioObject.h:150](_ak_audio_object_8h_source.html#l00150)

[AKMAKECLASSID](_ak_common_defs_8h_ac73a5e1e4a45a0aeea1b11b08ba93516.html#ac73a5e1e4a45a0aeea1b11b08ba93516)

#define AKMAKECLASSID(in\_pluginType, in\_companyID, in\_pluginID)

**Definition:** [AkCommonDefs.h:179](_ak_common_defs_8h_source.html#l00179)

[AK::IAkPluginMemAlloc](class_a_k_1_1_i_ak_plugin_mem_alloc.html)

**Definition:** [IAkPluginMemAlloc.h:42](_i_ak_plugin_mem_alloc_8h_source.html#l00041)

[AkMixerInputMap::Exists](class_ak_mixer_input_map_ad9acf848722f5fb49c1184fc89aff4a2.html#ad9acf848722f5fb49c1184fc89aff4a2)

USER\_DATA \* Exists(KEY in\_key)

Returns the user data associated with given input context. Returns NULL if none found.

**Definition:** [AkMixerInputMap.h:79](_ak_mixer_input_map_8h_source.html#l00079)

[AK\_ChannelConfigType\_Objects](_ak_enums_8h_a9e3e31d9ff388daa593222da7672a999.html#a9e3e31d9ff388daa593222da7672a999a338b59e9d7624cbc47fab92e22bc55cc)

@ AK\_ChannelConfigType\_Objects

Object-based configurations.

**Definition:** [AkEnums.h:408](_ak_enums_8h_source.html#l00408)

[AkAudioObjects::ppObjectBuffers](struct_ak_audio_objects_a0684629542f01bb629b5056edb4880e6.html#a0684629542f01bb629b5056edb4880e6)

AkAudioBuffer \*\* ppObjectBuffers

Array of pointers to audio object buffers.

**Definition:** [AkAudioObject.h:179](_ak_audio_object_8h_source.html#l00179)

[AkMixerInputMap::AddInput](class_ak_mixer_input_map_aa8e0ad3d5ecd8a24cc4c5011b4ffb1c9.html#aa8e0ad3d5ecd8a24cc4c5011b4ffb1c9)

USER\_DATA \* AddInput(KEY in\_key)

Adds an input with new user data.

**Definition:** [AkMixerInputMap.h:86](_ak_mixer_input_map_8h_source.html#l00086)

[AKASSERT](_ak_assert_8h_ac0e6cc4061c0a7c154a8c921a0af74cb.html#ac0e6cc4061c0a7c154a8c921a0af74cb)

#define AKASSERT(Condition)

**Definition:** [AkAssert.h:69](_ak_assert_8h_source.html#l00069)

[AkAudioObjects::uNumObjects](struct_ak_audio_objects_a9408cb0a160b5e02ce1bc2d2bd63e73a.html#a9408cb0a160b5e02ce1bc2d2bd63e73a)

AkUInt32 uNumObjects

Number of audio objects.

**Definition:** [AkAudioObject.h:178](_ak_audio_object_8h_source.html#l00178)

[AK::SpeakerVolumes::MatrixPtr](namespace_a_k_1_1_speaker_volumes_a57e0ce3a8225a58dd886853164554074.html#a57e0ce3a8225a58dd886853164554074)

AkSpeakerVolumesVectorPtr MatrixPtr

**Definition:** [AkTypedefs.h:96](_ak_typedefs_8h_source.html#l00096)

[AkAudioObject::arCustomMetadata](struct_ak_audio_object_a40f457c25d198d643eb3a93fd844771f.html#a40f457c25d198d643eb3a93fd844771f)

ArrayCustomMetadata arCustomMetadata

Array of custom metadata, gathered from visited objects. Note: any custom metadata is expected to exi...

**Definition:** [AkAudioObject.h:97](_ak_audio_object_8h_source.html#l00097)

[AkArray< AkInputMapSlot< KEY, USER\_DATA >, const AkInputMapSlot< KEY, USER\_DATA > &, AkPluginArrayAllocator >::End](class_ak_array_a8b3f475890ba0b28b1ee26ef26835789.html#a8b3f475890ba0b28b1ee26ef26835789)

Iterator End() const

Returns the iterator to the end of the array

**Definition:** [AkArray.h:354](_ak_array_8h_source.html#l00354)

[AkPositioningData::behavioral](struct_ak_positioning_data_ae7f86a6ffe7166f32371ec765111e8bb.html#ae7f86a6ffe7166f32371ec765111e8bb)

AkBehavioralPositioningData behavioral

Positioning data inherited from sound structures and mix busses.

**Definition:** [AkCommonDefs.h:280](_ak_common_defs_8h_source.html#l00280)

[AkTransform::Position](struct_ak_transform_a1b2697d425ca3e8e0a5fb0faee87fcd5.html#a1b2697d425ca3e8e0a5fb0faee87fcd5)

const AkVector & Position() const

Get position vector.

**Definition:** [Ak3DObjects.h:263](_ak3_d_objects_8h_source.html#l00263)

[AkMixerInputMap::EraseSwap](class_ak_mixer_input_map_ad839b271ff3a2213765456cefd569e5c.html#ad839b271ff3a2213765456cefd569e5c)

AkArray< AkInputMapSlot< KEY, USER\_DATA >, const AkInputMapSlot< KEY, USER\_DATA > &, AkPluginArrayAllocator >::Iterator EraseSwap(typename AkArray< AkInputMapSlot< KEY, USER\_DATA >, const AkInputMapSlot< KEY, USER\_DATA > &, AkPluginArrayAllocator >::Iterator &in\_rIter)

Erase the specified iterator in the array. but it does not guarantee the ordering in the array.

**Definition:** [AkMixerInputMap.h:123](_ak_mixer_input_map_8h_source.html#l00123)

[AkArray< AkInputMapSlot< KEY, USER\_DATA >, const AkInputMapSlot< KEY, USER\_DATA > &, AkPluginArrayAllocator >::Begin](class_ak_array_a3586641c10c90cdcbd2c67edc5361309.html#a3586641c10c90cdcbd2c67edc5361309)

Iterator Begin() const

Returns the iterator to the first item of the array, will be End() if the array is empty.

**Definition:** [AkArray.h:346](_ak_array_8h_source.html#l00346)

[AkPositioningData::threeD](struct_ak_positioning_data_a835e6eabecf9ecdf86fbf58bfe99d47b.html#a835e6eabecf9ecdf86fbf58bfe99d47b)

Ak3dData threeD

3D data used for 3D spatialization.

**Definition:** [AkCommonDefs.h:279](_ak_common_defs_8h_source.html#l00279)

[AkAudioObjectID](_ak_typedefs_8h_a6cadc0376ae4f945438db69f6306f21a.html#a6cadc0376ae4f945438db69f6306f21a)

AkUInt64 AkAudioObjectID

Audio Object ID

**Definition:** [AkTypedefs.h:67](_ak_typedefs_8h_source.html#l00067)

[AKRESULT](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63)

AKRESULT

**Definition:** [AkEnums.h:32](_ak_enums_8h_source.html#l00031)

[AkAudioObjects](struct_ak_audio_objects.html)

A collection of audio objects. Encapsulates the audio data and metadata of each audio object in separ...

**Definition:** [AkAudioObject.h:171](_ak_audio_object_8h_source.html#l00170)

[AkChannelConfig::SetStandard](struct_ak_channel_config_a4c0f4b3d39608a10c9b330c1ef8281a7.html#a4c0f4b3d39608a10c9b330c1ef8281a7)

AkForceInline void SetStandard(AkUInt32 in\_uChannelMask)

Set channel config as a standard configuration specified with given channel mask.

**Definition:** [AkSpeakerConfig.h:511](_ak_speaker_config_8h_source.html#l00511)

[AkUInt32](_ak_numeral_types_8h_a39c6c5d577901802ca77775760b704ce.html#a39c6c5d577901802ca77775760b704ce)

uint32\_t AkUInt32

Unsigned 32-bit integer

**Definition:** [AkNumeralTypes.h:35](_ak_numeral_types_8h_source.html#l00035)

[AkChannelConfig::eConfigType](struct_ak_channel_config_a598c4a4489e9fb252e7022ae99135674.html#a598c4a4489e9fb252e7022ae99135674)

AkUInt32 eConfigType

Channel config type (AkChannelConfigType).

**Definition:** [AkSpeakerConfig.h:445](_ak_speaker_config_8h_source.html#l00445)

[AK::IAkEffectPluginContext::CreateOutputObjects](class_a_k_1_1_i_ak_effect_plugin_context_a96f65eb02b520f2ca5af497e645971a0.html#a96f65eb02b520f2ca5af497e645971a0)

virtual AKRESULT CreateOutputObjects(AkChannelConfig in\_channelConfig, AkAudioObjects &io\_objects)=0

[AkAudioBuffer](class_ak_audio_buffer.html)

**Definition:** [AkCommonDefs.h:310](_ak_common_defs_8h_source.html#l00309)

[AkVector](struct_ak_vector.html)

3D vector for some operations in 3D space. Typically intended only for localized calculations due to ...

**Definition:** [Ak3DObjects.h:71](_ak3_d_objects_8h_source.html#l00070)

[AK\_SPEAKER\_SETUP\_STEREO](_ak_speaker_config_8h_a472757ac65daebc42373c503d4c3c894.html#a472757ac65daebc42373c503d4c3c894)

#define AK\_SPEAKER\_SETUP\_STEREO

2.0 setup channel mask

**Definition:** [AkSpeakerConfig.h:66](_ak_speaker_config_8h_source.html#l00066)

[AK\_Success](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63ad7c47fea3da641e7422573c6a13dc35e)

@ AK\_Success

The operation was successful.

**Definition:** [AkEnums.h:34](_ak_enums_8h_source.html#l00034)

[AkMixerInputMap](class_ak_mixer_input_map.html)

AkMixerInputMap: Map of inputs (identified with AK::IAkMixerInputContext \*) to user-defined blocks of...

**Definition:** [AkMixerInputMap.h:74](_ak_mixer_input_map_8h_source.html#l00073)

[AkAudioFormat](struct_ak_audio_format.html)

Defines the parameters of an audio buffer format.

**Definition:** [AkCommonDefs.h:61](_ak_common_defs_8h_source.html#l00060)

[AK::IAkEffectPluginContext](class_a_k_1_1_i_ak_effect_plugin_context.html)

**Definition:** [IAkPlugin.h:370](_i_ak_plugin_8h_source.html#l00369)

[Ak3dData::xform](struct_ak3d_data_a175ec6a58f0c97ab2070e23eb2b016db.html#a175ec6a58f0c97ab2070e23eb2b016db)

AkTransform xform

Object position / orientation.

**Definition:** [AkCommonDefs.h:246](_ak_common_defs_8h_source.html#l00246)

[AK\_UnsupportedChannelConfig](_ak_enums_8h_a64f7d1f79613cc4dcc49a4efba6caa63.html#a64f7d1f79613cc4dcc49a4efba6caa63a906fa026b1f04805d30bc474677e73ca)

@ AK\_UnsupportedChannelConfig

Channel configuration is not supported in the current execution context.

**Definition:** [AkEnums.h:79](_ak_enums_8h_source.html#l00079)

[AkAudioObjects::ppObjects](struct_ak_audio_objects_a4332a296e3e6d98688176aa460584853.html#a4332a296e3e6d98688176aa460584853)

AkAudioObject \*\* ppObjects

Array of pointers to audio objects.

**Definition:** [AkAudioObject.h:180](_ak_audio_object_8h_source.html#l00180)

[AK\_SpatializationMode\_None](_ak_enums_8h_a2091df555ad6110b01ce6905325a3a14.html#a2091df555ad6110b01ce6905325a3a14a1564e597be0cedb081025e92cd29aad2)

@ AK\_SpatializationMode\_None

No spatialization

**Definition:** [AkEnums.h:254](_ak_enums_8h_source.html#l00254)

[AkBehavioralPositioningData::spatMode](struct_ak_behavioral_positioning_data_a135aef56c3da0d202058e13af30ff950.html#a135aef56c3da0d202058e13af30ff950)

Ak3DSpatializationMode spatMode

3D spatialization mode.

**Definition:** [AkCommonDefs.h:271](_ak_common_defs_8h_source.html#l00271)

[AkAudioBuffer::MaxFrames](class_ak_audio_buffer_a537445dce6e3ed09dd2c337fd73c6b41.html#a537445dce6e3ed09dd2c337fd73c6b41)

AkForceInline AkUInt16 MaxFrames() const

**Definition:** [AkCommonDefs.h:489](_ak_common_defs_8h_source.html#l00489)